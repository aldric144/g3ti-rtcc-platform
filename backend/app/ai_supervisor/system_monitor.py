"""
Global System Monitor

Monitors all engines and subsystems across the RTCC-UIP platform:
- Drones, Robotics, Intel, Human Stability, Predictive AI
- City Autonomy, Global Awareness, Emergency Management
- Detects data corruption, API failures, latency spikes
- Tracks CPU, memory, GPU, queue congestion
- Identifies feedback loops and predicts system overload
"""

import hashlib
import random
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Optional


class EngineType(Enum):
    """Types of engines monitored by the system."""
    DRONE_TASK_FORCE = "drone_task_force"
    ROBOTICS = "robotics"
    INTEL_ORCHESTRATION = "intel_orchestration"
    HUMAN_STABILITY = "human_stability"
    PREDICTIVE_AI = "predictive_ai"
    CITY_AUTONOMY = "city_autonomy"
    GLOBAL_AWARENESS = "global_awareness"
    EMERGENCY_MANAGEMENT = "emergency_management"
    CYBER_INTEL = "cyber_intel"
    OFFICER_ASSIST = "officer_assist"
    CITY_BRAIN = "city_brain"
    ETHICS_GUARDIAN = "ethics_guardian"
    ENTERPRISE_INFRA = "enterprise_infra"
    NATIONAL_SECURITY = "national_security"
    DETECTIVE_AI = "detective_ai"
    THREAT_INTEL = "threat_intel"


class HealthStatus(Enum):
    """Health status levels for system components."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    WARNING = "warning"
    CRITICAL = "critical"
    OFFLINE = "offline"


class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class IssueType(Enum):
    """Types of system issues detected."""
    DATA_CORRUPTION = "data_corruption"
    API_FAILURE = "api_failure"
    LATENCY_SPIKE = "latency_spike"
    CPU_OVERLOAD = "cpu_overload"
    MEMORY_EXHAUSTION = "memory_exhaustion"
    GPU_OVERLOAD = "gpu_overload"
    QUEUE_CONGESTION = "queue_congestion"
    FEEDBACK_LOOP = "feedback_loop"
    SYSTEM_OVERLOAD = "system_overload"
    CONNECTION_FAILURE = "connection_failure"
    CACHE_CORRUPTION = "cache_corruption"
    MODEL_DRIFT = "model_drift"
    DATA_FEED_MISSING = "data_feed_missing"
    POLICY_CONFLICT = "policy_conflict"
    SECURITY_BREACH = "security_breach"


@dataclass
class EngineMetrics:
    """Metrics for a monitored engine."""
    engine_type: EngineType
    cpu_percent: float
    memory_percent: float
    gpu_percent: float
    queue_depth: int
    active_tasks: int
    latency_ms: float
    error_rate: float
    throughput_per_sec: float
    uptime_seconds: int
    last_heartbeat: datetime
    status: HealthStatus
    version: str
    instance_count: int
    timestamp: datetime = field(default_factory=datetime.utcnow)


@dataclass
class SystemAlert:
    """System alert generated by the monitor."""
    alert_id: str
    engine_type: EngineType
    issue_type: IssueType
    severity: AlertSeverity
    title: str
    description: str
    metrics: dict
    recommended_action: str
    auto_correctable: bool
    timestamp: datetime
    acknowledged: bool = False
    resolved: bool = False
    chain_of_custody_hash: str = ""


@dataclass
class FeedbackLoopDetection:
    """Detection of feedback loop in system."""
    detection_id: str
    source_engine: EngineType
    target_engine: EngineType
    loop_type: str
    cycle_time_ms: float
    amplification_factor: float
    risk_level: str
    mitigation_strategy: str
    timestamp: datetime
    chain_of_custody_hash: str = ""


@dataclass
class OverloadPrediction:
    """Prediction of system overload."""
    prediction_id: str
    engine_type: EngineType
    predicted_overload_time: datetime
    confidence: float
    contributing_factors: list
    current_load_percent: float
    projected_load_percent: float
    recommended_actions: list
    timestamp: datetime
    chain_of_custody_hash: str = ""


class SystemMonitor:
    """
    Global System Monitor for RTCC-UIP platform.
    
    Monitors all engines and subsystems, detects issues,
    and predicts system overload conditions.
    """
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        self.engine_metrics: dict[str, EngineMetrics] = {}
        self.alerts: dict[str, SystemAlert] = {}
        self.feedback_loops: dict[str, FeedbackLoopDetection] = {}
        self.overload_predictions: dict[str, OverloadPrediction] = {}
        
        self.thresholds = {
            "cpu_warning": 70.0,
            "cpu_critical": 90.0,
            "memory_warning": 75.0,
            "memory_critical": 90.0,
            "gpu_warning": 80.0,
            "gpu_critical": 95.0,
            "latency_warning_ms": 500,
            "latency_critical_ms": 2000,
            "error_rate_warning": 0.01,
            "error_rate_critical": 0.05,
            "queue_depth_warning": 1000,
            "queue_depth_critical": 5000,
        }
        
        self._initialize_engine_metrics()
        self._initialized = True
    
    def _initialize_engine_metrics(self):
        """Initialize metrics for all monitored engines."""
        for engine_type in EngineType:
            self.engine_metrics[engine_type.value] = EngineMetrics(
                engine_type=engine_type,
                cpu_percent=random.uniform(10, 50),
                memory_percent=random.uniform(20, 60),
                gpu_percent=random.uniform(5, 40),
                queue_depth=random.randint(0, 500),
                active_tasks=random.randint(1, 50),
                latency_ms=random.uniform(10, 200),
                error_rate=random.uniform(0, 0.005),
                throughput_per_sec=random.uniform(100, 1000),
                uptime_seconds=random.randint(3600, 86400 * 30),
                last_heartbeat=datetime.utcnow(),
                status=HealthStatus.HEALTHY,
                version="33.0",
                instance_count=random.randint(1, 5),
            )
    
    def _generate_hash(self, data: str) -> str:
        """Generate SHA256 hash for chain of custody."""
        return hashlib.sha256(f"{data}:{datetime.utcnow().isoformat()}".encode()).hexdigest()
    
    def get_engine_metrics(self, engine_type: EngineType) -> Optional[EngineMetrics]:
        """Get current metrics for a specific engine."""
        return self.engine_metrics.get(engine_type.value)
    
    def get_all_engine_metrics(self) -> list[EngineMetrics]:
        """Get metrics for all monitored engines."""
        return list(self.engine_metrics.values())
    
    def update_engine_metrics(
        self,
        engine_type: EngineType,
        cpu_percent: Optional[float] = None,
        memory_percent: Optional[float] = None,
        gpu_percent: Optional[float] = None,
        queue_depth: Optional[int] = None,
        active_tasks: Optional[int] = None,
        latency_ms: Optional[float] = None,
        error_rate: Optional[float] = None,
        throughput_per_sec: Optional[float] = None,
    ) -> EngineMetrics:
        """Update metrics for a specific engine."""
        metrics = self.engine_metrics.get(engine_type.value)
        if not metrics:
            raise ValueError(f"Unknown engine type: {engine_type}")
        
        if cpu_percent is not None:
            metrics.cpu_percent = cpu_percent
        if memory_percent is not None:
            metrics.memory_percent = memory_percent
        if gpu_percent is not None:
            metrics.gpu_percent = gpu_percent
        if queue_depth is not None:
            metrics.queue_depth = queue_depth
        if active_tasks is not None:
            metrics.active_tasks = active_tasks
        if latency_ms is not None:
            metrics.latency_ms = latency_ms
        if error_rate is not None:
            metrics.error_rate = error_rate
        if throughput_per_sec is not None:
            metrics.throughput_per_sec = throughput_per_sec
        
        metrics.last_heartbeat = datetime.utcnow()
        metrics.timestamp = datetime.utcnow()
        
        metrics.status = self._calculate_health_status(metrics)
        
        self._check_for_issues(metrics)
        
        return metrics
    
    def _calculate_health_status(self, metrics: EngineMetrics) -> HealthStatus:
        """Calculate health status based on metrics."""
        if metrics.cpu_percent >= self.thresholds["cpu_critical"] or \
           metrics.memory_percent >= self.thresholds["memory_critical"] or \
           metrics.error_rate >= self.thresholds["error_rate_critical"]:
            return HealthStatus.CRITICAL
        
        if metrics.cpu_percent >= self.thresholds["cpu_warning"] or \
           metrics.memory_percent >= self.thresholds["memory_warning"] or \
           metrics.latency_ms >= self.thresholds["latency_critical_ms"]:
            return HealthStatus.WARNING
        
        if metrics.latency_ms >= self.thresholds["latency_warning_ms"] or \
           metrics.error_rate >= self.thresholds["error_rate_warning"]:
            return HealthStatus.DEGRADED
        
        return HealthStatus.HEALTHY
    
    def _check_for_issues(self, metrics: EngineMetrics):
        """Check metrics for issues and generate alerts."""
        if metrics.cpu_percent >= self.thresholds["cpu_critical"]:
            self._create_alert(
                engine_type=metrics.engine_type,
                issue_type=IssueType.CPU_OVERLOAD,
                severity=AlertSeverity.CRITICAL,
                title=f"CPU Overload on {metrics.engine_type.value}",
                description=f"CPU usage at {metrics.cpu_percent:.1f}%",
                metrics={"cpu_percent": metrics.cpu_percent},
                recommended_action="Scale up instances or reduce load",
                auto_correctable=True,
            )
        
        if metrics.memory_percent >= self.thresholds["memory_critical"]:
            self._create_alert(
                engine_type=metrics.engine_type,
                issue_type=IssueType.MEMORY_EXHAUSTION,
                severity=AlertSeverity.CRITICAL,
                title=f"Memory Exhaustion on {metrics.engine_type.value}",
                description=f"Memory usage at {metrics.memory_percent:.1f}%",
                metrics={"memory_percent": metrics.memory_percent},
                recommended_action="Clear caches or restart service",
                auto_correctable=True,
            )
        
        if metrics.queue_depth >= self.thresholds["queue_depth_critical"]:
            self._create_alert(
                engine_type=metrics.engine_type,
                issue_type=IssueType.QUEUE_CONGESTION,
                severity=AlertSeverity.HIGH,
                title=f"Queue Congestion on {metrics.engine_type.value}",
                description=f"Queue depth at {metrics.queue_depth}",
                metrics={"queue_depth": metrics.queue_depth},
                recommended_action="Scale consumers or throttle producers",
                auto_correctable=True,
            )
        
        if metrics.latency_ms >= self.thresholds["latency_critical_ms"]:
            self._create_alert(
                engine_type=metrics.engine_type,
                issue_type=IssueType.LATENCY_SPIKE,
                severity=AlertSeverity.HIGH,
                title=f"Latency Spike on {metrics.engine_type.value}",
                description=f"Latency at {metrics.latency_ms:.1f}ms",
                metrics={"latency_ms": metrics.latency_ms},
                recommended_action="Check database connections and network",
                auto_correctable=False,
            )
        
        if metrics.error_rate >= self.thresholds["error_rate_critical"]:
            self._create_alert(
                engine_type=metrics.engine_type,
                issue_type=IssueType.API_FAILURE,
                severity=AlertSeverity.CRITICAL,
                title=f"High Error Rate on {metrics.engine_type.value}",
                description=f"Error rate at {metrics.error_rate * 100:.2f}%",
                metrics={"error_rate": metrics.error_rate},
                recommended_action="Check logs and restart if needed",
                auto_correctable=True,
            )
    
    def _create_alert(
        self,
        engine_type: EngineType,
        issue_type: IssueType,
        severity: AlertSeverity,
        title: str,
        description: str,
        metrics: dict,
        recommended_action: str,
        auto_correctable: bool,
    ) -> SystemAlert:
        """Create a new system alert."""
        alert_id = f"ALT-{hashlib.sha256(f'{engine_type.value}:{issue_type.value}:{datetime.utcnow().isoformat()}'.encode()).hexdigest()[:8].upper()}"
        
        alert = SystemAlert(
            alert_id=alert_id,
            engine_type=engine_type,
            issue_type=issue_type,
            severity=severity,
            title=title,
            description=description,
            metrics=metrics,
            recommended_action=recommended_action,
            auto_correctable=auto_correctable,
            timestamp=datetime.utcnow(),
            chain_of_custody_hash=self._generate_hash(f"{alert_id}:{title}"),
        )
        
        self.alerts[alert_id] = alert
        return alert
    
    def detect_data_corruption(
        self,
        engine_type: EngineType,
        data_source: str,
        expected_checksum: str,
        actual_checksum: str,
    ) -> Optional[SystemAlert]:
        """Detect data corruption in a data source."""
        if expected_checksum != actual_checksum:
            return self._create_alert(
                engine_type=engine_type,
                issue_type=IssueType.DATA_CORRUPTION,
                severity=AlertSeverity.CRITICAL,
                title=f"Data Corruption Detected in {data_source}",
                description=f"Checksum mismatch: expected {expected_checksum[:16]}..., got {actual_checksum[:16]}...",
                metrics={
                    "data_source": data_source,
                    "expected_checksum": expected_checksum,
                    "actual_checksum": actual_checksum,
                },
                recommended_action="Restore from backup and validate data integrity",
                auto_correctable=True,
            )
        return None
    
    def detect_feedback_loop(
        self,
        source_engine: EngineType,
        target_engine: EngineType,
        cycle_time_ms: float,
        amplification_factor: float,
    ) -> FeedbackLoopDetection:
        """Detect and record a feedback loop between engines."""
        detection_id = f"FBL-{hashlib.sha256(f'{source_engine.value}:{target_engine.value}:{datetime.utcnow().isoformat()}'.encode()).hexdigest()[:8].upper()}"
        
        if amplification_factor > 2.0:
            risk_level = "critical"
            loop_type = "amplifying"
        elif amplification_factor > 1.0:
            risk_level = "high"
            loop_type = "positive"
        elif amplification_factor < 0.5:
            risk_level = "low"
            loop_type = "dampening"
        else:
            risk_level = "medium"
            loop_type = "neutral"
        
        mitigation_strategy = self._get_feedback_loop_mitigation(loop_type, amplification_factor)
        
        detection = FeedbackLoopDetection(
            detection_id=detection_id,
            source_engine=source_engine,
            target_engine=target_engine,
            loop_type=loop_type,
            cycle_time_ms=cycle_time_ms,
            amplification_factor=amplification_factor,
            risk_level=risk_level,
            mitigation_strategy=mitigation_strategy,
            timestamp=datetime.utcnow(),
            chain_of_custody_hash=self._generate_hash(f"{detection_id}:{loop_type}"),
        )
        
        self.feedback_loops[detection_id] = detection
        
        if risk_level in ["critical", "high"]:
            self._create_alert(
                engine_type=source_engine,
                issue_type=IssueType.FEEDBACK_LOOP,
                severity=AlertSeverity.HIGH if risk_level == "high" else AlertSeverity.CRITICAL,
                title=f"Feedback Loop Detected: {source_engine.value} <-> {target_engine.value}",
                description=f"{loop_type.capitalize()} feedback loop with amplification factor {amplification_factor:.2f}",
                metrics={
                    "source_engine": source_engine.value,
                    "target_engine": target_engine.value,
                    "cycle_time_ms": cycle_time_ms,
                    "amplification_factor": amplification_factor,
                },
                recommended_action=mitigation_strategy,
                auto_correctable=True,
            )
        
        return detection
    
    def _get_feedback_loop_mitigation(self, loop_type: str, amplification_factor: float) -> str:
        """Get mitigation strategy for feedback loop."""
        if loop_type == "amplifying":
            return "Insert rate limiter and circuit breaker between engines"
        elif loop_type == "positive":
            return "Add dampening factor to reduce amplification"
        elif loop_type == "dampening":
            return "Monitor for signal loss, may need amplification"
        else:
            return "Continue monitoring, no immediate action required"
    
    def predict_system_overload(
        self,
        engine_type: EngineType,
        time_horizon_hours: int = 24,
    ) -> OverloadPrediction:
        """Predict system overload for an engine."""
        metrics = self.engine_metrics.get(engine_type.value)
        if not metrics:
            raise ValueError(f"Unknown engine type: {engine_type}")
        
        prediction_id = f"OLP-{hashlib.sha256(f'{engine_type.value}:{datetime.utcnow().isoformat()}'.encode()).hexdigest()[:8].upper()}"
        
        current_load = (metrics.cpu_percent + metrics.memory_percent + metrics.gpu_percent) / 3
        
        growth_rate = random.uniform(0.5, 2.0)
        projected_load = min(100, current_load * (1 + growth_rate * time_horizon_hours / 24))
        
        if projected_load >= 90:
            hours_to_overload = int((90 - current_load) / (growth_rate * current_load / 24))
            predicted_time = datetime.utcnow() + timedelta(hours=max(1, hours_to_overload))
            confidence = 0.85
        elif projected_load >= 80:
            hours_to_overload = int((90 - current_load) / (growth_rate * current_load / 24))
            predicted_time = datetime.utcnow() + timedelta(hours=max(1, hours_to_overload))
            confidence = 0.70
        else:
            predicted_time = datetime.utcnow() + timedelta(hours=time_horizon_hours * 2)
            confidence = 0.50
        
        contributing_factors = []
        if metrics.cpu_percent > 50:
            contributing_factors.append("High CPU utilization")
        if metrics.memory_percent > 50:
            contributing_factors.append("High memory utilization")
        if metrics.queue_depth > 500:
            contributing_factors.append("Queue backlog")
        if metrics.error_rate > 0.01:
            contributing_factors.append("Elevated error rate")
        
        recommended_actions = []
        if projected_load >= 80:
            recommended_actions.append("Scale up compute resources")
            recommended_actions.append("Enable auto-scaling")
        if metrics.queue_depth > 500:
            recommended_actions.append("Increase consumer capacity")
        if metrics.error_rate > 0.01:
            recommended_actions.append("Investigate and fix error sources")
        
        prediction = OverloadPrediction(
            prediction_id=prediction_id,
            engine_type=engine_type,
            predicted_overload_time=predicted_time,
            confidence=confidence,
            contributing_factors=contributing_factors,
            current_load_percent=current_load,
            projected_load_percent=projected_load,
            recommended_actions=recommended_actions,
            timestamp=datetime.utcnow(),
            chain_of_custody_hash=self._generate_hash(f"{prediction_id}:{projected_load}"),
        )
        
        self.overload_predictions[prediction_id] = prediction
        return prediction
    
    def get_system_health_summary(self) -> dict:
        """Get overall system health summary."""
        total_engines = len(self.engine_metrics)
        healthy_count = sum(1 for m in self.engine_metrics.values() if m.status == HealthStatus.HEALTHY)
        degraded_count = sum(1 for m in self.engine_metrics.values() if m.status == HealthStatus.DEGRADED)
        warning_count = sum(1 for m in self.engine_metrics.values() if m.status == HealthStatus.WARNING)
        critical_count = sum(1 for m in self.engine_metrics.values() if m.status == HealthStatus.CRITICAL)
        offline_count = sum(1 for m in self.engine_metrics.values() if m.status == HealthStatus.OFFLINE)
        
        avg_cpu = sum(m.cpu_percent for m in self.engine_metrics.values()) / total_engines
        avg_memory = sum(m.memory_percent for m in self.engine_metrics.values()) / total_engines
        avg_latency = sum(m.latency_ms for m in self.engine_metrics.values()) / total_engines
        
        active_alerts = [a for a in self.alerts.values() if not a.resolved]
        critical_alerts = [a for a in active_alerts if a.severity == AlertSeverity.CRITICAL]
        
        if critical_count > 0 or len(critical_alerts) > 0:
            overall_status = "CRITICAL"
        elif warning_count > 0:
            overall_status = "WARNING"
        elif degraded_count > 0:
            overall_status = "DEGRADED"
        else:
            overall_status = "HEALTHY"
        
        return {
            "overall_status": overall_status,
            "total_engines": total_engines,
            "healthy_count": healthy_count,
            "degraded_count": degraded_count,
            "warning_count": warning_count,
            "critical_count": critical_count,
            "offline_count": offline_count,
            "average_cpu_percent": round(avg_cpu, 2),
            "average_memory_percent": round(avg_memory, 2),
            "average_latency_ms": round(avg_latency, 2),
            "active_alerts": len(active_alerts),
            "critical_alerts": len(critical_alerts),
            "feedback_loops_detected": len(self.feedback_loops),
            "timestamp": datetime.utcnow().isoformat(),
        }
    
    def get_active_alerts(self, severity: Optional[AlertSeverity] = None) -> list[SystemAlert]:
        """Get active (unresolved) alerts."""
        alerts = [a for a in self.alerts.values() if not a.resolved]
        if severity:
            alerts = [a for a in alerts if a.severity == severity]
        return sorted(alerts, key=lambda a: a.timestamp, reverse=True)
    
    def acknowledge_alert(self, alert_id: str) -> bool:
        """Acknowledge an alert."""
        alert = self.alerts.get(alert_id)
        if alert:
            alert.acknowledged = True
            return True
        return False
    
    def resolve_alert(self, alert_id: str) -> bool:
        """Resolve an alert."""
        alert = self.alerts.get(alert_id)
        if alert:
            alert.resolved = True
            return True
        return False
    
    def get_statistics(self) -> dict:
        """Get system monitor statistics."""
        return {
            "total_engines_monitored": len(self.engine_metrics),
            "total_alerts_generated": len(self.alerts),
            "active_alerts": len([a for a in self.alerts.values() if not a.resolved]),
            "feedback_loops_detected": len(self.feedback_loops),
            "overload_predictions": len(self.overload_predictions),
            "timestamp": datetime.utcnow().isoformat(),
        }
